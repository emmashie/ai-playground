{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90fae5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Minimal linear-regression example with JAX.\n",
    "\n",
    "Requires:  pip install --upgrade \"jax[cpu]\"\n",
    "(or the GPU/CUDA build if you have CUDA installed.)\n",
    "\"\"\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Synthetic “dataset”: one 5-D input mapped to one 3-D target\n",
    "# -------------------------------------------------------------------\n",
    "x = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0])      # shape (5,)\n",
    "y_true = jnp.array([2.0, -1.0, 0.5])          # shape (3,)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Model parameters: weight matrix W (3×5) and bias b (3,)\n",
    "# -------------------------------------------------------------------\n",
    "key = jax.random.PRNGKey(0)\n",
    "W_init = jax.random.normal(key, (3, 5)) * 0.1\n",
    "b_init = jnp.zeros(3)\n",
    "params = (W_init, b_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f060bfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 1.0946617 , -0.80353975, -1.1520827 ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = jnp.dot(W_init, x) + b_init\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccdd8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Forward pass and loss\n",
    "# -------------------------------------------------------------------\n",
    "@jax.jit\n",
    "def predict(params, x):\n",
    "    W, b = params\n",
    "    return jnp.dot(W, x) + b                # linear map 5->3\n",
    "\n",
    "@jax.jit\n",
    "def mse_loss(params, x, y_true):\n",
    "    y_pred = predict(params, x)\n",
    "    return jnp.mean((y_pred - y_true) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8635bb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.1958704, dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(params, x, y_true)  # loss for initial params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353ef1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Training loop using vanilla stochastic-gradient descent\n",
    "# -------------------------------------------------------------------\n",
    "learning_rate = 1e-2\n",
    "grad_loss = jax.jit(jax.grad(mse_loss))             # ∇loss w.r.t. (W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "587e2725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[-0.6035589 , -1.2071178 , -1.8106767 , -2.4142356 , -3.0177946 ],\n",
       "        [ 0.1309735 ,  0.261947  ,  0.3929205 ,  0.523894  ,  0.65486753],\n",
       "        [-1.1013885 , -2.202777  , -3.3041654 , -4.405554  , -5.5069423 ]],      dtype=float32),\n",
       " Array([-0.6035589,  0.1309735, -1.1013885], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_loss(params, x, y_true)  # gradient for initial params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "404f15da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step    0 | loss = 0.4696317315\n",
      "step    1 | loss = 0.1844295710\n",
      "step    2 | loss = 0.0724275336\n",
      "step    3 | loss = 0.0284430813\n",
      "step    4 | loss = 0.0111699272\n",
      "step    5 | loss = 0.0043865554\n",
      "step    6 | loss = 0.0017226525\n",
      "step    7 | loss = 0.0006765013\n",
      "step    8 | loss = 0.0002656693\n",
      "step    9 | loss = 0.0001043317\n",
      "step   10 | loss = 0.0000409718\n",
      "\n",
      "Optimized weights W*:\n",
      " [[ 0.0245547   0.22312075  0.07777813  0.17638329  0.113793  ]\n",
      " [-0.08609448  0.0578374  -0.11399366 -0.09219912 -0.06283305]\n",
      " [ 0.09230851  0.14018224  0.05519871  0.0049707  -0.01943018]]\n",
      "\n",
      "Optimized bias b*:\n",
      " [ 0.01607213 -0.00348768  0.0293288 ]\n",
      "\n",
      "Prediction after training: [ 1.9947008  -0.9988501   0.49032986]\n",
      "Target: [ 2.  -1.   0.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(11):\n",
    "    grads = grad_loss(params, x, y_true)    # compute gradients\n",
    "\n",
    "    # Fancy way to update params:\n",
    "    # params = tuple(p - learning_rate * g    # SGD update\n",
    "    #                for p, g in zip(params, grads))\n",
    "\n",
    "    # Less fancy way to update params:\n",
    "    W, b = params\n",
    "    W_grad, b_grad = grads\n",
    "    W_update = W - learning_rate * W_grad\n",
    "    b_update = b - learning_rate * b_grad\n",
    "    params = (W_update, b_update)\n",
    "\n",
    "    print(f\"step {step:4d} | loss = {mse_loss(params, x, y_true):.10f}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Results\n",
    "# -------------------------------------------------------------------\n",
    "W_opt, b_opt = params\n",
    "print(\"\\nOptimized weights W*:\\n\", W_opt)\n",
    "print(\"\\nOptimized bias b*:\\n\", b_opt)\n",
    "print(\"\\nPrediction after training:\", predict(params, x))\n",
    "print(\"Target:\", y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff9a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bba90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seahorce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
